# Turing-compiler
an optimizing compiler to a binary turing machine

the syntax is fairly simplistic and we are stealing the perl lsp.
this is still in early devlopment so any bugs caught would be very apreshated.

mainly aimed at linux however nothing is inherently linux based in the compiler itself.
the build system just assumes bash instead of powershell. it should  be easy to fix if needed.
if there is demand I would open a windows brench

# usage
syntax exmples can be found in code_tests/tasks and in tests/code_samples
we use perl highlighting and a relativly free form of syntax.

as of now there are 3 major tools:
1. tape_tool: used to mainpulate .tape files 
2. run_turing: runs a turing machine described in .t on a .tape file and writes the output to anoter .tape file
3. tmc0: would compile a .t file into a binary when its done

this languge is really not ment to be written by hand for long periods of time.
the main intent is very big autogenerated machines. in  code_tests/code_gen.py you can see some examples of this.

currently using  export PATH=$(pwd)/bin:$PATH does not work with tmc0
because the path to io.o is derived programatically. this can be fixed in the future by directly basking io.o's binary into compiler.o as a string. 
or by using some sort of install system

# dependencies

### runtime 
we depend on asm and ld and libc. nothing more

### build
runtime+ gnumake gcc and bash.

### tests
build+ python (no packages)

# benchmarking
goto code_tests/test.sh to run the benchmarks

even the O0 compile run is consistently faster than the interpeters. this is very promicing since there is a lot wrong with tmc0 in terms of preformance.
it is made to be as simple as possible not to be fast

from the tests I ran on the interpeter it apears that not keeping track of the counter has a small yet semi consistent advantage.
the advantage could very well be caused by the need to parse another argument or something else that is as silly.
for most purposes it would probably not matter. the reason I am not using it is mainly because it simplifies some of the logic for the compiler.

## notes on the benchmarks
from playing around with code vs tape sizes its become pretty clear that the IO part can mess with the benchmark.
because of this it is recommanded to use smaller tapes for measuring.

# notes for devs
the make test system deletes the compiled files. since everything compiles under a second its not an issue. 
if this is not desirble test.py would work by itself. 

in code_tests there is a benchmarking codebase which can be used, it uses code generation.

# general plan
the idea is to wrap all of the syscalls into io.o and have that be a stable abi on all platforms.
then we generate intel asembly files that would need to be assembeled with nasm (I debated using opcodes but having it this way lets users read the assembly)
linking is done with ld

this means there is no gcc dependency!!! or any other compiler for that matter.



# TODO 

## compiler
1. add a way to benchmark old+new version of the compiler to asses changes
2. uninline the expand functions

## general
1. add a hex dump feature to tape_tool
2. unify the cli tools

## parser
1. add better error handeling with a dedicated struct.
